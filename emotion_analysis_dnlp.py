# -*- coding: utf-8 -*-
"""Emotion Analysis DNLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11OmvORTYJpUzFnLfCKsVqo9czCviEA_V

# **Emotion Analysis using DNLP**
"""

import numpy as np
import pandas as pd 
import tensorflow as tf
import matplotlib.pyplot as plt
import torch

df = pd.read_csv('train.csv', delimiter = ';', quoting = 3)
df.columns =['Title-Line', 'Type'] 
df=df.dropna(how='any')
df

print(df['Type'].unique())

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
df['Type']=le.fit_transform(df['Type'])

df['Type'].unique()

df

import re
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
corpus = []
for i in range(0, 15999):
  review = re.sub('[^a-zA-Z]', ' ', df['Title-Line'][i])
  review = review.lower()
  review = review.split()
  ps = PorterStemmer()
  all_stopwords = stopwords.words('english')
  all_stopwords.remove('not')
  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]
  review = ' '.join(review)
  corpus.append(review)

print(corpus)

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features = 1500)
X = cv.fit_transform(corpus).toarray()
y = df.iloc[:, -1].values

print(X)

len(X)

X[:1,:]

y

y=y.reshape(len(y),1)

len(y)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)

y_train = tf.keras.utils.to_categorical(y_train)
y_test = tf.keras.utils.to_categorical(y_test)

y_train

y_test

print("Initialized model")
ann = tf.keras.models.Sequential()
ann.add(tf.keras.layers.Dense(units=200, activation='relu'))
ann.add(tf.keras.layers.Dense(units=400, activation='relu'))
ann.add(tf.keras.layers.Dense(units=600, activation='relu'))
ann.add(tf.keras.layers.Dense(units=800, activation='relu'))
ann.add(tf.keras.layers.Dense(units=6, activation='softmax'))

ann.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = ann.fit(X_train, y_train, batch_size=15, epochs=10, validation_data=(X_test, y_test))
ann.save("EA-DNLP.h5")

plt.figure(0)
plt.plot(history.history['accuracy'], label='training accuracy')
plt.plot(history.history['val_accuracy'], label='val accuracy')
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
plt.savefig('Accuracy.png')
plt.figure(1)
plt.plot(history.history['loss'], label='training loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.title('Loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend()
plt.savefig('Loss.png')
print("Saved Model & Graph to disk")

model = tf.keras.models.load_model('EA-DNLP.h5')
print("Loaded model from disk")

DF=pd.read_csv('test.csv',delimiter = ';', quoting = 3)
DF.columns =['Title-Line', 'Type'] 
DF=DF.dropna(how='any')
DF

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
DF['Type']=le.fit_transform(DF['Type'])

DF

import re
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
c = []
for i in range(0, 1999):
  rev = re.sub('[^a-zA-Z]', ' ', DF['Title-Line'][i])
  rev= rev.lower()
  rev = rev.split()
  ps = PorterStemmer()
  all_stopwords = stopwords.words('english')
  all_stopwords.remove('not')
  rev = [ps.stem(word) for word in rev if not word in set(all_stopwords)]
  rev = ' '.join(rev)
  c.append(rev)

print(c)

len(c)

from sklearn.feature_extraction.text import CountVectorizer
Cv = CountVectorizer(max_features = 1500)
x = Cv.fit_transform(c).toarray()
a = DF.iloc[:, -1].values

x

len(x)

a

a = tf.keras.utils.to_categorical(a)

a

res=model.predict(x)
res=np.round(res)
np.set_printoptions(precision=2)
print(res)

len(res)

from sklearn.metrics import accuracy_score
print("Accuracy Score for the algorithm=>{}%".format(round(accuracy_score(a,res)*100),2))